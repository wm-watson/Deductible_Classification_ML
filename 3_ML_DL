import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV
from sklearn.metrics import (roc_auc_score, average_precision_score, precision_recall_curve,
                           classification_report, confusion_matrix, roc_curve, accuracy_score)
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
import time
import os
import joblib

# For Graph Neural Network
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, SAGEConv, global_mean_pool
from torch_geometric.data import Data, DataLoader
import networkx as nx

# Define the directory path
output_dir = r"R:\GraduateStudents\WatsonWilliamP\ML_DL_Deduc_Classification\Data"

# 1. Load the dataset
print("Loading dataset...")
csv_path = os.path.join(output_dir, "claim_level_features.csv")
claim_df = pd.read_csv(csv_path, low_memory=False)
print(f"Dataset loaded with {claim_df.shape[0]} rows and {claim_df.shape[1]} columns")

# 2. Prepare the target variable
print("\nPreparing target variable...")
target_column = 'DEDUCTIBLE_CATEGORY_first'
mask = claim_df[target_column].isin(['Aggregate', 'Embedded'])
filtered_df = claim_df[mask].copy()
filtered_df['target'] = (filtered_df[target_column] == 'Embedded').astype(int)
print(f"Target distribution: \n{filtered_df['target'].value_counts()}")
print(f"Imbalance ratio: 1:{filtered_df['target'].value_counts()[1]/filtered_df['target'].value_counts()[0]:.1f}")

# 3. Get the optimal features identified during feature selection
optimal_features = [
    'family_size_first_mean', 'DEDUCTIBLEAMOUNT_sum_mean', 'company_family_deductible_cv',
    'member_fam_deduct_amount_mean', 'fam_total_deduct_amount_mean', 'company_deductible_cv',
    'company_member_deductible_cv', 'insurance_covered_ratio', 'family_age_std',
    'fam_total_deduct_amount', 'never_has_coinsurance', 'family_deductible_to_company_avg',
    'deduct_per_family_member', 'family_mean_age', 'family_max_member_deduct',
    'family_years_in_data', 'member_deductible_to_company_avg', 'has_copay',
    'top_member_deduct_share', 'member_fam_deduct_amount'
]

print(f"\nUsing {len(optimal_features)} optimal features identified during feature selection")

# 4. Check if all features are in the dataset
missing_features = [f for f in optimal_features if f not in filtered_df.columns]
if missing_features:
    print(f"Warning: {len(missing_features)} features not found in dataset: {missing_features}")
    optimal_features = [f for f in optimal_features if f in filtered_df.columns]
    print(f"Proceeding with {len(optimal_features)} available features")

# 5. Prepare features and target
X = filtered_df[optimal_features].copy()
y = filtered_df['target']

# 6. Split into train, validation, and test sets
print("\nSplitting data into train, validation, and test sets...")

# First split to separate the test set
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Then split the remaining data into train and validation sets
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp
)  # 0.25 * 0.8 = 0.2 of original data

print(f"Training set: {X_train.shape[0]} samples ({X_train.shape[0]/X.shape[0]:.1%} of data)")
print(f"Validation set: {X_val.shape[0]} samples ({X_val.shape[0]/X.shape[0]:.1%} of data)")
print(f"Test set: {X_test.shape[0]} samples ({X_test.shape[0]/X.shape[0]:.1%} of data)")

# 7. Preprocessing pipeline
print("\nCreating preprocessing pipeline...")
preprocessor = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

# 8. Define standard ML models to test
models = {
    'Logistic Regression': LogisticRegression(class_weight='balanced', random_state=42),
    'Random Forest': RandomForestClassifier(class_weight='balanced', random_state=42),
    'Gradient Boosting': GradientBoostingClassifier(random_state=42),
    'SVM': SVC(probability=True, class_weight='balanced', random_state=42),
    'Neural Network': MLPClassifier(random_state=42, early_stopping=True, max_iter=100)
}

# 9. Function to evaluate a traditional ML model
def evaluate_model(model_name, model, X_train, y_train, X_val, y_val, X_test, y_test, use_smote=False):
    print(f"\nEvaluating {model_name}...")
    start_time = time.time()

    # Apply preprocessing to training, validation and test data
    X_train_processed = preprocessor.fit_transform(X_train)
    X_val_processed = preprocessor.transform(X_val)
    X_test_processed = preprocessor.transform(X_test)

    # Apply SMOTE if requested (only to training data)
    if use_smote:
        print("Applying SMOTE to balance training data...")
        smote = SMOTE(random_state=42)
        X_train_processed, y_train = smote.fit_resample(X_train_processed, y_train)
        print(f"After SMOTE - Training samples: {X_train_processed.shape[0]}")
        print(f"Class distribution: {np.bincount(y_train)}")

    # Train the model
    model.fit(X_train_processed, y_train)

    # Evaluate on validation set first
    val_pred_proba = model.predict_proba(X_val_processed)[:, 1]
    val_pred = model.predict(X_val_processed)
    val_auc = roc_auc_score(y_val, val_pred_proba)
    val_accuracy = accuracy_score(y_val, val_pred)

    print(f"Validation AUC: {val_auc:.4f}")
    print(f"Validation Accuracy: {val_accuracy:.4f}")

    # Make predictions on test set
    y_pred_proba = model.predict_proba(X_test_processed)[:, 1]
    y_pred = model.predict(X_test_processed)

    # Calculate metrics
    accuracy = accuracy_score(y_test, y_pred)
    auc = roc_auc_score(y_test, y_pred_proba)
    avg_precision = average_precision_score(y_test, y_pred_proba)

    # Classification report
    report = classification_report(y_test, y_pred, output_dict=True)

    # Confusion matrix
    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
    specificity = tn / (tn + fp)
    sensitivity = tp / (tp + fn)

    # Print results
    print(f"Training time: {time.time() - start_time:.2f} seconds")
    print(f"Test Accuracy: {accuracy:.4f}")
    print(f"Test AUC: {auc:.4f}")
    print(f"Test Average Precision: {avg_precision:.4f}")
    print(f"Test Sensitivity (Recall): {sensitivity:.4f}")
    print(f"Test Specificity: {specificity:.4f}")
    print("\nClassification Report (Test Set):")
    print(classification_report(y_test, y_pred))

    # Return results dictionary
    return {
        'model_name': model_name,
        'accuracy': accuracy,
        'auc': auc,
        'avg_precision': avg_precision,
        'sensitivity': sensitivity,
        'specificity': specificity,
        'f1_aggregate': report['0']['f1-score'],
        'f1_embedded': report['1']['f1-score'],
        'model': model,
        'val_auc': val_auc,
        'val_accuracy': val_accuracy,
        'y_test': y_test,
        'y_pred_proba': y_pred_proba,
        'y_pred': y_pred,
        'support_aggregate': report['0']['support'],
        'support_embedded': report['1']['support']
    }

# 10. Evaluate base ML models
print("\nEvaluating traditional ML models...")
base_results = []

for model_name, model in models.items():
    # Skip SVM for large datasets (too slow)
    if model_name == 'SVM' and X_train.shape[0] > 10000:
        print(f"Skipping {model_name} - dataset too large for efficient training")
        continue

    # Evaluate without SMOTE first
    result = evaluate_model(model_name, model, X_train, y_train, X_val, y_val, X_test, y_test, use_smote=False)
    base_results.append(result)

# 11. Define and prepare GNN model
print("\nPreparing Graph Neural Network model...")
try:
    # Check if we have necessary family relationship data
    required_cols = ['family_id', 'MVDID', 'SUBSCRIBERID']
    has_family_data = any(col in filtered_df.columns for col in required_cols)

    if not has_family_data:
        print("Warning: Family relationship data not found. Creating synthetic relationships for GNN demo.")
        # Create synthetic family IDs if not available
        if 'family_id' not in filtered_df.columns:
            filtered_df['family_id'] = filtered_df.index // 3  # Create synthetic family groups

    # Function to create a graph from the dataset
    def create_graph_data(df, features, target, family_col='family_id'):
        print("Creating graph from data...")

        # Create a mapping from original indices to new node indices
        df = df.reset_index(drop=True)
        node_mapping = {idx: i for i, idx in enumerate(df.index)}

        # Preprocess features
        X_graph = preprocessor.fit_transform(df[features])
        X_graph = torch.tensor(X_graph, dtype=torch.float)

        # Create edge index: connect members of the same family
        edge_index = []
        family_groups = df.groupby(family_col)

        for family, members in family_groups:
            # Create edges between all members in the family (fully connected)
            member_indices = members.index.tolist()
            if len(member_indices) > 1:  # Only create edges if there are at least 2 members
                for i in range(len(member_indices)):
                    for j in range(i+1, len(member_indices)):
                        source = node_mapping[member_indices[i]]
                        target = node_mapping[member_indices[j]]
                        # Create bidirectional edges
                        edge_index.append([source, target])
                        edge_index.append([target, source])

        # Convert to torch tensor
        if edge_index:  # Check if we have any edges
            edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()
        else:
            # If no family connections, create self-loops
            print("Warning: No family connections found. Creating self-loops for each node.")
            indices = list(range(len(df)))
            edge_index = torch.tensor([indices, indices], dtype=torch.long)

        # Convert targets to tensor
        y_graph = torch.tensor(df[target].values, dtype=torch.long)

        # Create PyTorch Geometric Data object
        data = Data(x=X_graph, edge_index=edge_index, y=y_graph)
        return data

    # Define a GNN model
    class GNN(torch.nn.Module):
        def __init__(self, input_dim, hidden_dim=64, output_dim=2):
            super(GNN, self).__init__()
            self.conv1 = GCNConv(input_dim, hidden_dim)
            self.conv2 = GCNConv(hidden_dim, hidden_dim)
            self.lin1 = nn.Linear(hidden_dim, hidden_dim)
            self.lin2 = nn.Linear(hidden_dim, output_dim)

        def forward(self, data):
            x, edge_index = data.x, data.edge_index

            # First Graph Conv layer with ReLU
            x = self.conv1(x, edge_index)
            x = F.relu(x)
            x = F.dropout(x, p=0.3, training=self.training)

            # Second Graph Conv layer with ReLU
            x = self.conv2(x, edge_index)
            x = F.relu(x)

            # MLP for final predictions
            x = self.lin1(x)
            x = F.relu(x)
            x = F.dropout(x, p=0.3, training=self.training)
            x = self.lin2(x)

            return F.log_softmax(x, dim=1)

    # Function to evaluate the GNN model
    def evaluate_gnn(gnn_model, train_data, val_data, test_data, epochs=100, lr=0.01):
        print("\nEvaluating Graph Neural Network model...")
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"Using device: {device}")

        # Move model and data to device
        model = gnn_model.to(device)
        train_data = train_data.to(device)
        val_data = val_data.to(device)
        test_data = test_data.to(device)

        # Initialize optimizer
        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)

        # Training loop
        start_time = time.time()
        model.train()
        best_val_loss = float('inf')
        patience = 10
        counter = 0

        print("Starting GNN training...")
        for epoch in range(epochs):
            optimizer.zero_grad()
            out = model(train_data)
            loss = F.nll_loss(out, train_data.y)
            loss.backward()
            optimizer.step()

            # Evaluate on validation set
            model.eval()
            with torch.no_grad():
                val_out = model(val_data)
                val_loss = F.nll_loss(val_out, val_data.y)

                # Compute validation metrics
                val_pred_proba = torch.exp(val_out)[:, 1].cpu().numpy()
                _, val_pred = val_out.max(dim=1)
                val_pred = val_pred.cpu().numpy()
                val_true = val_data.y.cpu().numpy()
                val_accuracy = accuracy_score(val_true, val_pred)
                val_auc = roc_auc_score(val_true, val_pred_proba)
            model.train()

            # Early stopping check
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                counter = 0
                # Save best model
                best_model_state = model.state_dict().copy()
            else:
                counter += 1

            if counter >= patience:
                print(f"Early stopping at epoch {epoch}")
                break

            if (epoch + 1) % 10 == 0:
                print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}, Val AUC: {val_auc:.4f}')

        train_time = time.time() - start_time
        print(f"Training completed in {train_time:.2f} seconds")

        # Load best model for evaluation
        model.load_state_dict(best_model_state)

        # Evaluation
        model.eval()
        with torch.no_grad():
            # Validation set final evaluation
            val_out = model(val_data)
            val_pred_proba = torch.exp(val_out)[:, 1].cpu().numpy()
            _, val_pred = val_out.max(dim=1)
            val_true = val_data.y.cpu().numpy()
            val_accuracy = accuracy_score(val_true, val_pred)
            val_auc = roc_auc_score(val_true, val_pred_proba)

            print(f"Final validation accuracy: {val_accuracy:.4f}")
            print(f"Final validation AUC: {val_auc:.4f}")

            # Test set evaluation
            out = model(test_data)
            pred_proba = torch.exp(out)[:, 1].cpu().numpy()
            _, pred = out.max(dim=1)
            pred = pred.cpu().numpy()

            # Get target values
            y_true = test_data.y.cpu().numpy()

            # Calculate metrics
            accuracy = accuracy_score(y_true, pred)
            auc = roc_auc_score(y_true, pred_proba)
            avg_precision = average_precision_score(y_true, pred_proba)
            report = classification_report(y_true, pred, output_dict=True)

            # Confusion matrix
            tn, fp, fn, tp = confusion_matrix(y_true, pred).ravel()
            specificity = tn / (tn + fp)
            sensitivity = tp / (tp + fn)

            print(f"Test Accuracy: {accuracy:.4f}")
            print(f"Test AUC: {auc:.4f}")
            print(f"Test Average Precision: {avg_precision:.4f}")
            print(f"Test Sensitivity (Recall): {sensitivity:.4f}")
            print(f"Test Specificity: {specificity:.4f}")

            return {
                'model_name': 'Graph Neural Network',
                'accuracy': accuracy,
                'auc': auc,
                'avg_precision': avg_precision,
                'sensitivity': sensitivity,
                'specificity': specificity,
                'f1_aggregate': report['0']['f1-score'],
                'f1_embedded': report['1']['f1-score'],
                'model': model,
                'val_auc': val_auc,
                'val_accuracy': val_accuracy,
                'y_test': y_true,
                'y_pred_proba': pred_proba,
                'y_pred': pred,
                'support_aggregate': report['0']['support'],
                'support_embedded': report['1']['support']
            }

    # Create train/val/test graph data
    train_indices = X_train.index
    val_indices = X_val.index
    test_indices = X_test.index

    train_df = filtered_df.loc[train_indices].copy()
    val_df = filtered_df.loc[val_indices].copy()
    test_df = filtered_df.loc[test_indices].copy()

    train_data = create_graph_data(train_df, optimal_features, 'target')
    val_data = create_graph_data(val_df, optimal_features, 'target')
    test_data = create_graph_data(test_df, optimal_features, 'target')

    print(f"Graph data created - Train: {len(train_data.x)} nodes, Val: {len(val_data.x)} nodes, Test: {len(test_data.x)} nodes")
    print(f"Train edges: {train_data.edge_index.shape}")
    print(f"Val edges: {val_data.edge_index.shape}")
    print(f"Test edges: {test_data.edge_index.shape}")

    # Create and evaluate GNN model
    input_dim = len(optimal_features)
    gnn_model = GNN(input_dim=input_dim, hidden_dim=64, output_dim=2)

    print("Model architecture:")
    print(gnn_model)

    # Train and evaluate GNN
    gnn_result = evaluate_gnn(gnn_model, train_data, val_data, test_data, epochs=200, lr=0.01)
    base_results.append(gnn_result)

except Exception as e:
    print(f"Error with GNN implementation: {str(e)}")
    print("Skipping GNN model and continuing with traditional ML models")

# 12. Compare all model results
print("\nModel comparison:")
base_df = pd.DataFrame(base_results)
performance_cols = ['model_name', 'val_accuracy', 'val_auc', 'accuracy', 'auc', 'avg_precision', 'sensitivity', 'specificity',
                    'f1_aggregate', 'f1_embedded']
print(base_df[performance_cols])

# 13. Try SMOTE with the best performing traditional model
# Choose based on validation AUC
best_trad_model_idx = base_df[~base_df['model_name'].str.contains('Graph Neural Network')]['val_auc'].idxmax()
best_trad_model_name = base_df.loc[best_trad_model_idx, 'model_name']
print(f"\nApplying SMOTE to the best traditional model: {best_trad_model_name}")
best_model = models[best_trad_model_name]
smote_result = evaluate_model(f"{best_trad_model_name} with SMOTE", best_model,
                             X_train, y_train, X_val, y_val, X_test, y_test, use_smote=True)
base_results.append(smote_result)

# 14. Hyperparameter tuning for the best traditional model
print(f"\nPerforming hyperparameter tuning for {best_trad_model_name}...")

# Define parameter grids for each model type
param_grids = {
    'Logistic Regression': {
        'C': [0.01, 0.1, 1, 10, 100],
        'solver': ['liblinear', 'saga']
    },
    'Random Forest': {
        'n_estimators': [100, 200],
        'max_depth': [None, 10, 20],
        'min_samples_split': [2, 5, 10]
    },
    'Gradient Boosting': {
        'n_estimators': [100, 200],
        'learning_rate': [0.01, 0.1],
        'max_depth': [3, 5]
    },
    'SVM': {
        'C': [0.1, 1, 10],
        'gamma': ['scale', 'auto'],
        'kernel': ['rbf', 'linear']
    },
    'Neural Network': {
        'hidden_layer_sizes': [(50,), (100,), (50, 50)],
        'alpha': [0.0001, 0.001, 0.01],
        'learning_rate_init': [0.001, 0.01]
    }
}

# Get parameter grid for the best model
if best_trad_model_name in param_grids:
    param_grid = param_grids[best_trad_model_name]

    # Apply preprocessing to training and validation data
    X_train_processed = preprocessor.fit_transform(X_train)
    X_val_processed = preprocessor.transform(X_val)

    # Combine train and validation for CV
    X_train_val = np.vstack((X_train_processed, X_val_processed))
    y_train_val = np.concatenate((y_train, y_val))

    # Create grid search
    grid_search = GridSearchCV(
        estimator=best_model,
        param_grid=param_grid,
        scoring='roc_auc',
        cv=3,
        n_jobs=-1,
        verbose=1
    )

    # Fit grid search
    print("Running grid search...")
    start_time = time.time()
    grid_search.fit(X_train_val, y_train_val)
    print(f"Grid search completed in {time.time() - start_time:.2f} seconds")

    # Get best parameters
    print(f"Best parameters: {grid_search.best_params_}")
    print(f"Best cross-validation score: {grid_search.best_score_:.4f}")

    # Create a new model with best parameters
    model_class = type(best_model)
    best_params = grid_search.best_params_

    # Add any fixed parameters that should be kept
    if best_trad_model_name in ['Random Forest', 'Logistic Regression']:
        best_params['class_weight'] = 'balanced'
    best_params['random_state'] = 42

    # Instantiate tuned model with best parameters
    best_tuned_model = model_class(**best_params)

    # Evaluate tuned model
    tuned_result = evaluate_model(f"{best_trad_model_name} (tuned)", best_tuned_model,
                                 X_train, y_train, X_val, y_val, X_test, y_test, use_smote=False)
    base_results.append(tuned_result)

    # Try tuned model with SMOTE
    tuned_smote_result = evaluate_model(f"{best_trad_model_name} (tuned) with SMOTE", best_tuned_model,
                                      X_train, y_train, X_val, y_val, X_test, y_test, use_smote=True)
    base_results.append(tuned_smote_result)
else:
    print(f"No parameter grid defined for {best_trad_model_name}")

# 15. Final comparison of all models
print("\nFinal model comparison:")
final_df = pd.DataFrame(base_results)
print(final_df[performance_cols])

# 16. Visualizations
print("\nCreating visualizations...")

# ROC curves
plt.figure(figsize=(10, 8))
for result in base_results:
    model_name = result['model_name']
    y_test = result['y_test']
    y_pred_proba = result['y_pred_proba']

    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
    auc = result['auc']
    plt.plot(fpr, tpr, label=f"{model_name} (AUC = {auc:.4f})")

plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curves')
plt.legend()
roc_path = os.path.join(output_dir, "roc_curves.png")
plt.savefig(roc_path)
print(f"ROC curves saved to {roc_path}")

# Precision-Recall curves
plt.figure(figsize=(10, 8))
for result in base_results:
    model_name = result['model_name']
    y_test = result['y_test']
    y_pred_proba = result['y_pred_proba']

    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)
    avg_precision = result['avg_precision']
    plt.plot(recall, precision, label=f"{model_name} (AP = {avg_precision:.4f})")

plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curves')
plt.legend()
pr_path = os.path.join(output_dir, "precision_recall_curves.png")
plt.savefig(pr_path)
print(f"Precision-Recall curves saved to {pr_path}")

# Feature importance for the best model (if available)
if best_trad_model_name in ['Random Forest', 'Gradient Boosting']:
    # Find the best tuned model result
    best_tuned_idx = final_df[final_df['model_name'].str.contains('tuned') &
                             ~final_df['model_name'].str.contains('SMOTE')]['val_auc'].idxmax()
    best_tuned_result = base_results[best_tuned_idx]
    best_tuned_model = best_tuned_result['model']

    # Get feature importances
    importances = best_tuned_model.feature_importances_
    indices = np.argsort(importances)[::-1]

    # Plot feature importances
    plt.figure(figsize=(12, 8))
    plt.title(f'Feature Importances ({best_trad_model_name})')
    plt.bar(range(X.shape[1]), importances[indices])
    plt.xticks(range(X.shape[1]), [optimal_features[i] for i in indices], rotation=90)
    plt.tight_layout()
    imp_path = os.path.join(output_dir, "feature_importances.png")
    plt.savefig(imp_path)
    print(f"Feature importances saved to {imp_path}")

# 17. Save the best model
# Select best model based on validation AUC
best_final_idx = final_df['val_auc'].idxmax()
best_final_result = base_results[best_final_idx]
best_final_name = best_final_result['model_name']

print(f"\nBest overall model: {best_final_name} with validation AUC = {best_final_result['val_auc']:.4f}")
print(f"Test AUC of best model: {best_final_result['auc']:.4f}")

# Special handling for GNN model vs traditional models
if 'Graph Neural Network' in best_final_name:
    print("Best model is a Graph Neural Network. Saving the model separately.")
    torch.save(best_final_result['model'].state_dict(), os.path.join(output_dir, "best_gnn_model.pt"))

    # Also save preprocessing for future use with GNN
    joblib.dump(preprocessor, os.path.join(output_dir, "gnn_preprocessor.joblib"))

    # Save info about graph structure
    graph_info = {
        'input_dim': len(optimal_features),
        'features': optimal_features
    }
    with open(os.path.join(output_dir, "gnn_info.txt"), 'w') as f:
        f.write(f"Input dimensions: {graph_info['input_dim']}\n")
        f.write("Features:\n")
        for feature in graph_info['features']:
            f.write(f"- {feature}\n")
else:
    # For traditional models, save as a pipeline
    best_trad_model = best_final_result['model']
    best_pipeline = Pipeline([
        ('preprocessor', preprocessor),
        ('model', best_trad_model)
    ])

    # Save the pipeline
    model_path = os.path.join(output_dir, "best_model_pipeline.joblib")
    joblib.dump(best_pipeline, model_path)
    print(f"Best model pipeline saved to {model_path}")

# 18. Save model performance comparison
comparison_path = os.path.join(output_dir, "model_comparison.csv")
final_df[performance_cols].to_csv(comparison_path, index=False)
print(f"Model comparison saved to {comparison_path}")

# 19. Create a feature explanation output
print("\nCreating feature explanation...")

# Prepare a DataFrame for feature analysis
feature_analysis = pd.DataFrame({
    'Feature': optimal_features
})

# Add mean values for each class
for target_val, target_name in [(0, 'Aggregate'), (1, 'Embedded')]:
    target_mask = filtered_df['target'] == target_val
    for feature in optimal_features:
        feature_analysis.loc[feature_analysis['Feature'] == feature, f'{target_name}_Mean'] = \
            filtered_df.loc[target_mask, feature].mean()

# Calculate absolute difference between means
feature_analysis['Mean_Diff_Abs'] = abs(feature_analysis['Aggregate_Mean'] - feature_analysis['Embedded_Mean'])

# Calculate percent difference
feature_analysis['Mean_Diff_Pct'] = (
    (feature_analysis['Embedded_Mean'] - feature_analysis['Aggregate_Mean']) /
    feature_analysis['Aggregate_Mean'].replace(0, np.nan)  # Avoid division by zero
).fillna(0) * 100

# Add standard deviations
for target_val, target_name in [(0, 'Aggregate'), (1, 'Embedded')]:
    target_mask = filtered_df['target'] == target_val
    for feature in optimal_features:
        feature_analysis.loc[feature_analysis['Feature'] == feature, f'{target_name}_StdDev'] = \
            filtered_df.loc[target_mask, feature].std()

# Sort by absolute mean difference
feature_analysis = feature_analysis.sort_values('Mean_Diff_Abs', ascending=False)

# Save feature analysis
feature_analysis_path = os.path.join(output_dir, "feature_analysis.csv")
feature_analysis.to_csv(feature_analysis_path, index=False)
print(f"Feature analysis saved to {feature_analysis_path}")

# 20. Create boxplots for top discriminating features
print("\nCreating boxplots for top discriminating features...")

# Get top 5 features by mean difference
top_features = feature_analysis.head(5)['Feature'].tolist()

# Create boxplots
plt.figure(figsize=(15, 10))
for i, feature in enumerate(top_features):
    plt.subplot(2, 3, i+1)
    sns.boxplot(x='target', y=feature, data=filtered_df, palette='Set3')
    plt.title(feature)
    plt.xlabel('0=Aggregate, 1=Embedded')

plt.tight_layout()
boxplot_path = os.path.join(output_dir, "top_features_boxplots.png")
plt.savefig(boxplot_path)
print(f"Feature boxplots saved to {boxplot_path}")

# 21. Visualize the graph structure (if GNN was successful)
try:
    if 'Graph Neural Network' in final_df['model_name'].values:
        print("\nCreating graph visualization...")
        # Create a smaller sample for visualization
        sample_size = min(500, len(filtered_df))
        sample_df = filtered_df.sample(sample_size, random_state=42)

        # Create a NetworkX graph
        G = nx.Graph()

        # Add nodes with properties
        for idx, row in sample_df.reset_index().iterrows():
            # Use deductible type as node color
            node_color = 'red' if row['target'] == 1 else 'blue'
            G.add_node(idx, color=node_color, label=f"Node {idx}")

        # Add edges based on family connections
        family_groups = sample_df.groupby('family_id')
        for family, members in family_groups:
            member_indices = members.index.tolist()
            if len(member_indices) > 1:  # Only create edges if there are at least 2 members
                for i in range(len(member_indices)):
                    for j in range(i+1, len(member_indices)):
                        G.add_edge(i, j, weight=1)

        # Draw the graph
        plt.figure(figsize=(12, 12))
        node_colors = [G.nodes[n]['color'] for n in G.nodes]

        pos = nx.spring_layout(G, seed=42)
        nx.draw(G, pos, node_color=node_colors, node_size=50,
                with_labels=False, alpha=0.8, edge_color='gray')

        # Add a legend
        red_patch = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Embedded')
        blue_patch = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=10, label='Aggregate')
        plt.legend(handles=[red_patch, blue_patch], loc='upper right')

        plt.title('Family Relationship Graph (Sample)')
        graph_viz_path = os.path.join(output_dir, "family_graph_visualization.png")
        plt.savefig(graph_viz_path)
        print(f"Graph visualization saved to {graph_viz_path}")
except Exception as e:
    print(f"Error creating graph visualization: {str(e)}")

print("\nML model analysis complete!")
